---
title: 'Overview of custom models'
description: 'Learn how to optimize and deploy custom models with the Exla SDK'
---

# Custom Models Overview

The Exla SDK provides powerful hardware-aware optimization for your custom machine learning models. With just a few lines of code, you can dramatically improve inference speed and reduce model size while maintaining accuracy.

## Quick Start: Optimize Your Model

Optimizing your model with Exla is as simple as:

```python
from exla.optimize import optimize_model
import torch

# Load and optimize your model
model_path = "your_model.pt"
optimized_model = optimize_model(model_path)

# Run inference with the optimized model
input_tensor = torch.randn(1, 3, 224, 224).cuda()
predictions = optimized_model(input_tensor)
```

### Example using a pre-trained model

**Download the model**
```python
import torch
import torchvision.models as models

# Load the pretrained EfficientNet-B0 model
model = models.efficientnet_b0(pretrained=True)
model.eval()  # set to evaluation mode

# Save the full model locally (this saves both architecture and weights)
torch.save(model, "efficientnet_b0_full.pt")
```

**Optimize the model**
```python
from exla.optimize import optimize_model
import torch

# Load and optimize the model with FP16 precision
model_path = "efficientnet_b0_full.pt"
optimized_model = optimize_model(
    model_path
)

# Run inference with batch size 1
# Random input to represent an RGB image
input_tensor = torch.randn(1, 3, 224, 224).cuda()
predictions = optimized_model(input_tensor)
    
# Print top 5 predictions
probs = torch.nn.functional.softmax(predictions[0], dim=0)
_, top5_indices = torch.topk(probs, 5)
print("\nTop 5 predictions:")
for idx in top5_indices:
    print(f"Class {idx.item()}: {probs[idx].item()*100:.1f}%")
```
## Supported Model Formats

Exla supports models from popular frameworks:
- PyTorch (`.pth`, `.pt`)
- TorchScript
- ONNX (`.onnx`)
- TensorFlow SavedModel

## What is happening behind the scenes?

Exla employs several sophisticated techniques to optimize your models:

### 1. TensorRT Compilation

For GPU targets, Exla uses TensorRT to compile your model with optimizations like:

- **Operation Fusion**: Combines multiple operations (e.g., Conv+BatchNorm+ReLU) into single, optimized kernels
- **Kernel Auto-Tuning**: Selects the most efficient implementation for your specific GPU
- **Memory Access Optimization**: Improves memory access patterns for faster execution
- **Dynamic Tensor Memory**: Efficiently reuses memory during inference

### 2. Precision Optimization

Exla supports multiple precision levels to balance accuracy and performance:

- **FP32 (32-bit floating point)**: Baseline precision with no accuracy loss
- **FP16 (16-bit floating point)**: ~2x smaller models with minimal accuracy impact
- **INT8 (8-bit integer quantization)**: ~4x smaller models with significant speed improvements
- **INT4 (4-bit integer quantization)**: ~8x smaller models with significant speed improvements
- **Lower precision support coming soon**

```python
# Specify precision during optimization
optimized_model = optimize_model(
    model_path,
    precision="fp16"  # Options: "fp32", "fp16", "int8"
)
```

### 3. ZeroQ Quantization

Exla implements ZeroQ, a data-free quantization technique that:

- Generates synthetic calibration data matching your model's statistics
- Optimizes quantization parameters without requiring real data
- Preserves accuracy by analyzing BatchNorm statistics
- Enables INT8 quantization with minimal accuracy loss

Under the hood, Exla:
1. Analyzes your model's BatchNorm layers
2. Generates synthetic data that matches the statistical distribution
3. Uses this data to calibrate the quantization process
4. Verifies accuracy against the original model

### 4. Workspace Memory Optimization

Exla carefully manages GPU memory usage:

```python
# Configure workspace memory
optimized_model = optimize_model(
    model_path,
    workspace_size=1 << 20  # 1 MB workspace
)
```

### 5. Dynamic Shape Support

For models that need to handle variable input sizes:

```python
# Enable dynamic shape support
optimized_model = optimize_model(
    model_path,
    dynamic_shape=True
)
```

## Performance Improvements

When you optimize a model with Exla, you can expect:

- **2-5x faster inference** depending on the model and hardware
- **50-75% reduction in memory usage** with quantization
- **4x smaller model size** with INT8 quantization
- **Minimal accuracy loss** with our precision-preserving techniques

## Behind the Scenes: The Optimization Pipeline

Here's what happens when you call `optimize_model()`:

1. **Model Analysis**
   - Loads your model and analyzes its architecture
   - Determines the optimal optimization strategy
   - Measures baseline performance metrics

2. **Synthetic Data Generation**
   - Creates calibration data using BatchNorm statistics
   - Ensures quantization preserves the model's statistical properties
   - Eliminates the need for real calibration data

3. **TensorRT Compilation**
   - Converts your model to TensorRT format
   - Applies kernel fusion and other optimizations
   - Selects the most efficient implementation for your GPU

4. **Accuracy Verification**
   - Compares predictions between original and optimized models
   - Ensures top-1 and top-5 accuracy remain high
   - Validates that optimization preserves model behavior

5. **Performance Measurement**
   - Benchmarks inference speed
   - Measures memory usage reduction
   - Calculates overall speedup factor
