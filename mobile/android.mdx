---
title: "Android SDK"
description: "Run Llama 3.2 3B locally on your Android device"
---

# Exla AI SDK for Android

The Exla Android SDK allows you to run state-of-the-art AI text generation directly on your Android device, without requiring an internet connection for inference.

## Features

- ðŸš€ **Fully On-Device**: All processing happens on your device, ensuring privacy and offline usage
- ðŸ“± **Optimized for Mobile**: Uses quantized models specifically designed for mobile devices
- âš¡ **Fast Responses**: Efficient implementation for quick text generation
- ðŸ§  **Llama 3.2 3B**: Powered by Meta's latest Llama 3.2 3B Instruct model

## Installation

Add JitPack repository to your project's `settings.gradle.kts`:

```kotlin
dependencyResolutionManagement {
    repositories {
        google()
        mavenCentral()
        maven { url = uri("https://jitpack.io") }
    }
}
```

Then add the Exla AI SDK dependency to your app's `build.gradle.kts`:

```kotlin
dependencies {
    implementation("com.github.exla-ai:exla-android-sdk:v1.0.0-alpha01")
}
```

## Using the SDK

### 1. Initialize the SDK

```kotlin
// Get the SDK instance
val sdk = ExlaAiSdk.getInstance(context)

// Initialize and download the model (first run only)
sdk.initialize(
    progressCallback = { progress -> 
        // Update UI with download progress (0-100)
        progressBar.progress = progress
    },
    completionCallback = { success ->
        if (success) {
            // Model loaded successfully
            statusText.text = "Model ready!"
        } else {
            // Model download or initialization failed
            statusText.text = "Model initialization failed"
        }
    }
)
```

### 2. Generate Text

Once the model is loaded, you can generate text responses:

```kotlin
// Check if the model is ready
if (sdk.isReady()) {
    // Ask a question
    sdk.askAI("What is machine learning?") { response ->
        // Update UI with the response
        outputText.text = response
    }
}
```

### 3. Model Details

The SDK automatically downloads and uses Llama 3.2 3B Instruct (Q2_K.gguf) - a 2-bit quantized version of the Llama 3.2 3B model optimized for mobile devices.

- **Model Size**: ~1.3GB download
- **Capabilities**: Text completion, question answering, simple reasoning
- **Languages**: Primarily English, with limited support for other languages
- **Context Window**: 2048 tokens

## Example App

Here's a complete example of a simple chat interface:

```kotlin
class MainActivity : AppCompatActivity() {
    private lateinit var sdk: ExlaAiSdk
    
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)
        
        // Get SDK instance
        sdk = ExlaAiSdk.getInstance(applicationContext)
        
        // Set up download button
        findViewById<Button>(R.id.downloadButton).setOnClickListener {
            downloadModel()
        }
        
        // Set up chat button
        findViewById<Button>(R.id.sendButton).setOnClickListener {
            val prompt = findViewById<EditText>(R.id.promptInput).text.toString()
            if (prompt.isNotEmpty()) {
                generateResponse(prompt)
            }
        }
    }
    
    private fun downloadModel() {
        val progressBar = findViewById<ProgressBar>(R.id.progressBar)
        val statusText = findViewById<TextView>(R.id.statusText)
        
        progressBar.visibility = View.VISIBLE
        statusText.text = "Downloading model..."
        
        sdk.initialize(
            progressCallback = { progress -> 
                progressBar.progress = progress
                statusText.text = "Downloading: $progress%"
            },
            completionCallback = { success ->
                progressBar.visibility = View.GONE
                statusText.text = if (success) "Model ready!" else "Download failed"
            }
        )
    }
    
    private fun generateResponse(prompt: String) {
        val outputText = findViewById<TextView>(R.id.outputText)
        
        if (!sdk.isReady()) {
            outputText.text = "Please download the model first"
            return
        }
        
        outputText.text = "Generating response..."
        
        sdk.askAI(prompt) { response ->
            runOnUiThread {
                outputText.text = response
            }
        }
    }
}
```

## Requirements

- Android 7.0 (API level 24) or higher
- Approximately 2.5GB of free storage space
- At least 4GB of RAM recommended

## Privacy

All text generation happens entirely on your device. The SDK only connects to the internet once to download the model file.
